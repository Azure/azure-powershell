// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License. See License.txt in the project root for license information.
// Code generated by Microsoft (R) AutoRest Code Generator.
// Changes may cause incorrect behavior and will be lost if the code is regenerated.

namespace Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101
{
    using static Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Runtime.Extensions;

    /// <summary>
    /// Describes the settings to be used when encoding the input video into a desired output bitrate layer with the H.264 video
    /// codec.
    /// </summary>
    public partial class H264Layer :
        Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.IH264Layer,
        Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.IH264LayerInternal,
        Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Runtime.IValidates
    {
        /// <summary>
        /// Backing field for Inherited model <see cref= "Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.IVideoLayer"
        /// />
        /// </summary>
        private Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.IVideoLayer __videoLayer = new Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.VideoLayer();

        /// <summary>
        /// Whether or not adaptive B-frames are to be used when encoding this layer. If not specified, the encoder will turn it on
        /// whenever the video profile permits its use.
        /// </summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Origin(Microsoft.Azure.PowerShell.Cmdlets.MediaServices.PropertyOrigin.Inherited)]
        public bool? AdaptiveBFrame { get => ((Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.IVideoLayerInternal)__videoLayer).AdaptiveBFrame; set => ((Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.IVideoLayerInternal)__videoLayer).AdaptiveBFrame = value ?? default(bool); }

        /// <summary>
        /// The number of B-frames to be used when encoding this layer. If not specified, the encoder chooses an appropriate number
        /// based on the video profile and level.
        /// </summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Origin(Microsoft.Azure.PowerShell.Cmdlets.MediaServices.PropertyOrigin.Inherited)]
        public int? BFrame { get => ((Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.IVideoLayerInternal)__videoLayer).BFrame; set => ((Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.IVideoLayerInternal)__videoLayer).BFrame = value ?? default(int); }

        /// <summary>
        /// The average bitrate in bits per second at which to encode the input video when generating this layer. This is a required
        /// field.
        /// </summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Origin(Microsoft.Azure.PowerShell.Cmdlets.MediaServices.PropertyOrigin.Inherited)]
        public int Bitrate { get => ((Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.IVideoLayerInternal)__videoLayer).Bitrate; set => ((Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.IVideoLayerInternal)__videoLayer).Bitrate = value ; }

        /// <summary>Backing field for <see cref="BufferWindow" /> property.</summary>
        private global::System.TimeSpan? _bufferWindow;

        /// <summary>
        /// The VBV buffer window length. The value should be in ISO 8601 format. The value should be in the range [0.1-100] seconds.
        /// The default is 5 seconds (for example, PT5S).
        /// </summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Origin(Microsoft.Azure.PowerShell.Cmdlets.MediaServices.PropertyOrigin.Owned)]
        public global::System.TimeSpan? BufferWindow { get => this._bufferWindow; set => this._bufferWindow = value; }

        /// <summary>Backing field for <see cref="Crf" /> property.</summary>
        private float? _crf;

        /// <summary>
        /// The value of CRF to be used when encoding this layer. This setting takes effect when RateControlMode of video codec is
        /// set at CRF mode. The range of CRF value is between 0 and 51, where lower values would result in better quality, at the
        /// expense of higher file sizes. Higher values mean more compression, but at some point quality degradation will be noticed.
        /// Default value is 23.
        /// </summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Origin(Microsoft.Azure.PowerShell.Cmdlets.MediaServices.PropertyOrigin.Owned)]
        public float? Crf { get => this._crf; set => this._crf = value; }

        /// <summary>Backing field for <see cref="EntropyMode" /> property.</summary>
        private Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Support.EntropyMode? _entropyMode;

        /// <summary>
        /// The entropy mode to be used for this layer. If not specified, the encoder chooses the mode that is appropriate for the
        /// profile and level.
        /// </summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Origin(Microsoft.Azure.PowerShell.Cmdlets.MediaServices.PropertyOrigin.Owned)]
        public Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Support.EntropyMode? EntropyMode { get => this._entropyMode; set => this._entropyMode = value; }

        /// <summary>
        /// The frame rate (in frames per second) at which to encode this layer. The value can be in the form of M/N where M and N
        /// are integers (For example, 30000/1001), or in the form of a number (For example, 30, or 29.97). The encoder enforces constraints
        /// on allowed frame rates based on the profile and level. If it is not specified, the encoder will use the same frame rate
        /// as the input video.
        /// </summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Origin(Microsoft.Azure.PowerShell.Cmdlets.MediaServices.PropertyOrigin.Inherited)]
        public string FrameRate { get => ((Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.IVideoLayerInternal)__videoLayer).FrameRate; set => ((Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.IVideoLayerInternal)__videoLayer).FrameRate = value ?? null; }

        /// <summary>
        /// The height of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For
        /// example 50% means the output video has half as many pixels in height as the input.
        /// </summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Origin(Microsoft.Azure.PowerShell.Cmdlets.MediaServices.PropertyOrigin.Inherited)]
        public string Height { get => ((Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.ILayerInternal)__videoLayer).Height; set => ((Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.ILayerInternal)__videoLayer).Height = value ?? null; }

        /// <summary>
        /// The alphanumeric label for this layer, which can be used in multiplexing different video and audio layers, or in naming
        /// the output file.
        /// </summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Origin(Microsoft.Azure.PowerShell.Cmdlets.MediaServices.PropertyOrigin.Inherited)]
        public string Label { get => ((Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.ILayerInternal)__videoLayer).Label; set => ((Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.ILayerInternal)__videoLayer).Label = value ?? null; }

        /// <summary>Backing field for <see cref="Level" /> property.</summary>
        private string _level;

        /// <summary>
        /// We currently support Level up to 6.2. The value can be Auto, or a number that matches the H.264 profile. If not specified,
        /// the default is Auto, which lets the encoder choose the Level that is appropriate for this layer.
        /// </summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Origin(Microsoft.Azure.PowerShell.Cmdlets.MediaServices.PropertyOrigin.Owned)]
        public string Level { get => this._level; set => this._level = value; }

        /// <summary>
        /// The maximum bitrate (in bits per second), at which the VBV buffer should be assumed to refill. If not specified, defaults
        /// to the same value as bitrate.
        /// </summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Origin(Microsoft.Azure.PowerShell.Cmdlets.MediaServices.PropertyOrigin.Inherited)]
        public int? MaxBitrate { get => ((Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.IVideoLayerInternal)__videoLayer).MaxBitrate; set => ((Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.IVideoLayerInternal)__videoLayer).MaxBitrate = value ?? default(int); }

        /// <summary>Backing field for <see cref="Profile" /> property.</summary>
        private Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Support.H264VideoProfile? _profile;

        /// <summary>We currently support Baseline, Main, High, High422, High444. Default is Auto.</summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Origin(Microsoft.Azure.PowerShell.Cmdlets.MediaServices.PropertyOrigin.Owned)]
        public Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Support.H264VideoProfile? Profile { get => this._profile; set => this._profile = value; }

        /// <summary>Backing field for <see cref="ReferenceFrame" /> property.</summary>
        private int? _referenceFrame;

        /// <summary>
        /// The number of reference frames to be used when encoding this layer. If not specified, the encoder determines an appropriate
        /// number based on the encoder complexity setting.
        /// </summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Origin(Microsoft.Azure.PowerShell.Cmdlets.MediaServices.PropertyOrigin.Owned)]
        public int? ReferenceFrame { get => this._referenceFrame; set => this._referenceFrame = value; }

        /// <summary>
        /// The number of slices to be used when encoding this layer. If not specified, default is zero, which means that encoder
        /// will use a single slice for each frame.
        /// </summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Origin(Microsoft.Azure.PowerShell.Cmdlets.MediaServices.PropertyOrigin.Inherited)]
        public int? Slice { get => ((Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.IVideoLayerInternal)__videoLayer).Slice; set => ((Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.IVideoLayerInternal)__videoLayer).Slice = value ?? default(int); }

        /// <summary>
        /// The width of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example
        /// 50% means the output video has half as many pixels in width as the input.
        /// </summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Origin(Microsoft.Azure.PowerShell.Cmdlets.MediaServices.PropertyOrigin.Inherited)]
        public string Width { get => ((Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.ILayerInternal)__videoLayer).Width; set => ((Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.ILayerInternal)__videoLayer).Width = value ?? null; }

        /// <summary>Creates an new <see cref="H264Layer" /> instance.</summary>
        public H264Layer()
        {

        }

        /// <summary>Validates that this object meets the validation criteria.</summary>
        /// <param name="eventListener">an <see cref="Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Runtime.IEventListener" /> instance that will receive validation
        /// events.</param>
        /// <returns>
        /// A <see cref = "global::System.Threading.Tasks.Task" /> that will be complete when validation is completed.
        /// </returns>
        public async global::System.Threading.Tasks.Task Validate(Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Runtime.IEventListener eventListener)
        {
            await eventListener.AssertNotNull(nameof(__videoLayer), __videoLayer);
            await eventListener.AssertObjectIsValid(nameof(__videoLayer), __videoLayer);
        }
    }
    /// Describes the settings to be used when encoding the input video into a desired output bitrate layer with the H.264 video
    /// codec.
    public partial interface IH264Layer :
        Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Runtime.IJsonSerializable,
        Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.IVideoLayer
    {
        /// <summary>
        /// The VBV buffer window length. The value should be in ISO 8601 format. The value should be in the range [0.1-100] seconds.
        /// The default is 5 seconds (for example, PT5S).
        /// </summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Runtime.Info(
        Required = false,
        ReadOnly = false,
        Description = @"The VBV buffer window length. The value should be in ISO 8601 format. The value should be in the range [0.1-100] seconds. The default is 5 seconds (for example, PT5S).",
        SerializedName = @"bufferWindow",
        PossibleTypes = new [] { typeof(global::System.TimeSpan) })]
        global::System.TimeSpan? BufferWindow { get; set; }
        /// <summary>
        /// The value of CRF to be used when encoding this layer. This setting takes effect when RateControlMode of video codec is
        /// set at CRF mode. The range of CRF value is between 0 and 51, where lower values would result in better quality, at the
        /// expense of higher file sizes. Higher values mean more compression, but at some point quality degradation will be noticed.
        /// Default value is 23.
        /// </summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Runtime.Info(
        Required = false,
        ReadOnly = false,
        Description = @"The value of CRF to be used when encoding this layer. This setting takes effect when RateControlMode of video codec is set at CRF mode. The range of CRF value is between 0 and 51, where lower values would result in better quality, at the expense of higher file sizes. Higher values mean more compression, but at some point quality degradation will be noticed. Default value is 23.",
        SerializedName = @"crf",
        PossibleTypes = new [] { typeof(float) })]
        float? Crf { get; set; }
        /// <summary>
        /// The entropy mode to be used for this layer. If not specified, the encoder chooses the mode that is appropriate for the
        /// profile and level.
        /// </summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Runtime.Info(
        Required = false,
        ReadOnly = false,
        Description = @"The entropy mode to be used for this layer. If not specified, the encoder chooses the mode that is appropriate for the profile and level.",
        SerializedName = @"entropyMode",
        PossibleTypes = new [] { typeof(Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Support.EntropyMode) })]
        Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Support.EntropyMode? EntropyMode { get; set; }
        /// <summary>
        /// We currently support Level up to 6.2. The value can be Auto, or a number that matches the H.264 profile. If not specified,
        /// the default is Auto, which lets the encoder choose the Level that is appropriate for this layer.
        /// </summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Runtime.Info(
        Required = false,
        ReadOnly = false,
        Description = @"We currently support Level up to 6.2. The value can be Auto, or a number that matches the H.264 profile. If not specified, the default is Auto, which lets the encoder choose the Level that is appropriate for this layer.",
        SerializedName = @"level",
        PossibleTypes = new [] { typeof(string) })]
        string Level { get; set; }
        /// <summary>We currently support Baseline, Main, High, High422, High444. Default is Auto.</summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Runtime.Info(
        Required = false,
        ReadOnly = false,
        Description = @"We currently support Baseline, Main, High, High422, High444. Default is Auto.",
        SerializedName = @"profile",
        PossibleTypes = new [] { typeof(Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Support.H264VideoProfile) })]
        Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Support.H264VideoProfile? Profile { get; set; }
        /// <summary>
        /// The number of reference frames to be used when encoding this layer. If not specified, the encoder determines an appropriate
        /// number based on the encoder complexity setting.
        /// </summary>
        [Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Runtime.Info(
        Required = false,
        ReadOnly = false,
        Description = @"The number of reference frames to be used when encoding this layer. If not specified, the encoder determines an appropriate number based on the encoder complexity setting.",
        SerializedName = @"referenceFrames",
        PossibleTypes = new [] { typeof(int) })]
        int? ReferenceFrame { get; set; }

    }
    /// Describes the settings to be used when encoding the input video into a desired output bitrate layer with the H.264 video
    /// codec.
    internal partial interface IH264LayerInternal :
        Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Models.Api20211101.IVideoLayerInternal
    {
        /// <summary>
        /// The VBV buffer window length. The value should be in ISO 8601 format. The value should be in the range [0.1-100] seconds.
        /// The default is 5 seconds (for example, PT5S).
        /// </summary>
        global::System.TimeSpan? BufferWindow { get; set; }
        /// <summary>
        /// The value of CRF to be used when encoding this layer. This setting takes effect when RateControlMode of video codec is
        /// set at CRF mode. The range of CRF value is between 0 and 51, where lower values would result in better quality, at the
        /// expense of higher file sizes. Higher values mean more compression, but at some point quality degradation will be noticed.
        /// Default value is 23.
        /// </summary>
        float? Crf { get; set; }
        /// <summary>
        /// The entropy mode to be used for this layer. If not specified, the encoder chooses the mode that is appropriate for the
        /// profile and level.
        /// </summary>
        Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Support.EntropyMode? EntropyMode { get; set; }
        /// <summary>
        /// We currently support Level up to 6.2. The value can be Auto, or a number that matches the H.264 profile. If not specified,
        /// the default is Auto, which lets the encoder choose the Level that is appropriate for this layer.
        /// </summary>
        string Level { get; set; }
        /// <summary>We currently support Baseline, Main, High, High422, High444. Default is Auto.</summary>
        Microsoft.Azure.PowerShell.Cmdlets.MediaServices.Support.H264VideoProfile? Profile { get; set; }
        /// <summary>
        /// The number of reference frames to be used when encoding this layer. If not specified, the encoder determines an appropriate
        /// number based on the encoder complexity setting.
        /// </summary>
        int? ReferenceFrame { get; set; }

    }
}